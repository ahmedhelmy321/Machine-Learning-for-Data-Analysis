{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b6d3fd",
   "metadata": {},
   "source": [
    "Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ede7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# قراءة البيانات من ملف CSV او اى نوع ملف اخر مع تغيير read_csv الى read_excel او read_json حسب نوع الملف\n",
    "data=pd.read_csv(\"file path\")\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# التعامل مع القيم المفقودة\n",
    "# حذف الصفوف الناقصة\n",
    "df_drop = df.dropna()\n",
    "\n",
    "\n",
    "\n",
    "# تعويض القيم المفقودة بالمتوسط\n",
    "df_fill_mean = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "\n",
    "\n",
    "# تعويض القيم المفقودة بالقيمة الأكثر تكراراً\n",
    "df_fill_mode = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "\n",
    "\n",
    "# التعامل مع القيم الشاذة (Outliers) باستخدام IQR \n",
    "Q1 = df['coulmn name'].quantile(0.25)\n",
    "Q3 = df['coulmn name'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df_outliers = df[(df['coulmn name'] >= Q1 - 1.5*IQR) & (df['coulmn name'] <= Q3 + 1.5*IQR)]\n",
    "\n",
    "\n",
    "\n",
    "# إزالة البيانات المكررة \n",
    "df_unique = df.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "# after that we have cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b768f",
   "metadata": {},
   "source": [
    "Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "#Normalization\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df.select_dtypes(include=[np.number])), columns=df.select_dtypes(include=[np.number]).columns)\n",
    "\n",
    "\n",
    "# standardization\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler.fit_transform(df.select_dtypes(include=[np.number])), columns=df.select_dtypes(include=[np.number]).columns)\n",
    "\n",
    "# تحويل البيانات النصيه الى قيم رقمية\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_column'] = label_encoder.fit_transform(df['categorical_column'])\n",
    "\n",
    "# One-Hot Encoding\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = onehot_encoder.fit_transform(df[['categorical_column']])\n",
    "df_onehot = pd.DataFrame(encoded_features, columns=onehot_encoder.get_feature_names_out(['categorical_column']))\n",
    "df = pd.concat([df, df_onehot], axis=1).drop('categorical_column', axis=1)\n",
    "\n",
    "# تقسيم البيانات إلى ميزات وهدف (Features and Target)\n",
    "X = df.drop('target_column', axis=1)\n",
    "y = df['target_column']\n",
    "\n",
    "\n",
    "# الآن البيانات جاهزة للنمذجة\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d096d2f5",
   "metadata": {},
   "source": [
    "Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df['numerical_column'], bins=30, kde=True)\n",
    "plt.title('Distribution of Numerical Column')\n",
    "plt.xlabel('Numerical Column')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Box Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='categorical_column', y='numerical_column', data=df)\n",
    "plt.title('Box Plot of Numerical Column by Categorical Column')\n",
    "plt.xlabel('Categorical Column')\n",
    "plt.ylabel('Numerical Column')\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='numerical_column1', y='numerical_column2', hue='categorical_column', data=df)\n",
    "plt.title('Scatter Plot of Numerical Column1 vs Numerical Column2')\n",
    "plt.xlabel('Numerical Column1')\n",
    "plt.ylabel('Numerical Column2')\n",
    "plt.show()\n",
    "\n",
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(12,8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6cc368",
   "metadata": {},
   "source": [
    "\n",
    "Now we have excellent data and we can model it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73383f3",
   "metadata": {},
   "source": [
    "If we are making a classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b5374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#  importing  classification models\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# تقسيم البيانات إلى مجموعة تدريب واختبار\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Random Forest Classifier\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"LogisticRegression\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"SVC\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"KNeighborsClassifier\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"DecisionTreeClassifier\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"AdaBoostClassifier\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"GradientBoostingClassifier\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"XGBClassifier\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "model = CatBoostClassifier(verbose=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"CatBoostClassifier\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdfea68",
   "metadata": {},
   "source": [
    "If we are making a regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#regression\n",
    "from sklearn.model_selection import train_test_split    \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#  importing  regression models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.ensemble import AdaBoostRegressor \n",
    "from sklearn.tree import DecisionTreeRegressore\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "# تقسيم البيانات إلى مجموعة تدريب واختبار\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Linear Regression\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Random Forest Regressor\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Gradient Boosting Regressor\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"AdaBoost Regressor\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "model = DecisionTreeRegressore()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Decision Tree Regressor\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"KNeighbors Regressor\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "model = SVR()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Support Vector Regressor\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"XGB Regressor\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "model = CatBoostRegressor(verbose=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"CatBoost Regressor\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f221317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL SAVING \n",
    "import joblib\n",
    "joblib.dump(model, \"model.pkl\")\n",
    "loaded_model = joblib.load(\"model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904aeeb",
   "metadata": {},
   "source": [
    "when have un supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4535ada",
   "metadata": {},
   "source": [
    "Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624500e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=y, cmap=\"viridis\")\n",
    "plt.title(\"PCA - 2D Projection\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n",
    "\n",
    "# t-SNE (للتصور فقط)\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_tsne[:,0], X_tsne[:,1], c=y, cmap=\"plasma\")\n",
    "plt.title(\"t-SNE Visualization\")\n",
    "plt.xlabel(\"Dim1\")\n",
    "plt.ylabel(\"Dim2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96540288",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3364c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# KMeans Clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "print(\"KMeans Silhouette Score:\", silhouette_score(X, clusters))\n",
    "\n",
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "clusters = dbscan.fit_predict(X)\n",
    "print(\"DBSCAN Labels:\", set(clusters))  # -1 = noise\n",
    "\n",
    "# Agglomerative Clustering\n",
    "agg = AgglomerativeClustering(n_clusters=3)\n",
    "clusters = agg.fit_predict(X)\n",
    "print(\"AgglomerativeClustering Silhouette Score:\", silhouette_score(X, clusters))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
